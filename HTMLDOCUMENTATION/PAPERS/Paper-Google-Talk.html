<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Paper-Google-Talk</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height; auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="fresh-perspectives">Fresh Perspectives</h1>
<blockquote>
<p>A Google Talk on 11/1/2011 by Bruce Wilcox</p>
</blockquote>
<p>If you are the kind of person who takes notes during a talk, you
won’t need to. A pdf copy will be available at the end.</p>
<p>I am an AI research engineer. I want to create things that people
use, but that stretch the boundaries of the possible. Whatever I work
on, I research it and then try to come at it with a fresh
perspective.</p>
<p>A fresh perspective is something Google and I have in common, though
we approach things from opposite directions. Typically my fresh
perspectives involve understanding a domain and then writing a new
application-specific scripting language to encapsulate insights I have
gleaned. Google’s perspectives come from access to massive amounts of
data and hardware.</p>
<p>I research everything. I even researched how to give this talk. I
thought about making a lot of clever PowerPoint slides. Then I read up
on using and abusing PowerPoint. I abandoned that plan.</p>
<p>I’m going to walk you through earlier days of my professional life
for a moment, before focusing in on my natural language stuff. That way
maybe you’ll better understand what I do and how I approach things.</p>
<p>I started out in the early days of AI, when LISP was de rigeur. I
became a knowledge engineer. A knowledge engineer gets into the mind of
an expert in some domain, learns how he thinks, and tries to program it.
I’ve done that a few times now.</p>
<h2 id="go">Go</h2>
<p>My first such task was to write a program to play the oriental game
of Go. It was actually my job. The major LISP systems of the day were
too slow, particularly for a game application requiring lookahead, so in
preparation I wrote my own LISP interpreter, MTS-LISP. It was the start
of my career writing application-specific scripting languages. MTS-LISP
was fast, particularly for searching game trees. Coincidentally, it was
also the LISP system Peter Norvig used at Brown.</p>
<p>Go has a 4000 year history. It’s a game which has been studied
endlessly in the Orient and for which professional schools have existed
since the middle ages. Yet I was unique in all that history. Everyone
else who learned Go did so to play the game. They learned and then
forgot what they learned as it became internalized. I learned Go to
program it, a fresh perspective. I learned consciously, watching what I
learned so I could code it, reanalyzing what I learned so I could
reinterpret it.</p>
<p>Fast forward 5 years. I had become a strong amateur player and a
world-renowned Go teacher and theorist. Not only had my fresh
perspective lead to a workable theory for programming Go, but I
fundamentally shifted the conceptual landscape of Western Go.</p>
<p>I was the East Coast amateur champion, in a playoff against the West
Coast one to see who would represent the US at the World Amateur’s. I
played an opening sequence unknown to everyone, something I called the
Great Wall. A game of Go lasts about 250 moves. By the end of my first
five, every strong player there knew I had a lost position. All my moves
had completely violated the knowledge Go players throughout the world
are taught as mere beginners. Not only was my opening game wrong, but I
attacked my opponent’s positions and defended my own with moves no one
had seen before. The game ended with my opponent losing by a large
margin. The strong players spent hours on replays trying to determine
where things had gone wrong. They never found it. I was playing with a
completely different map of the game. Had they asked me, I would have
said that he lost on his tenth move, playing what they all thought was
excellent and obvious.</p>
<p>I wrote a bunch of popular articles on my theories called <em>Instant
Go</em>, which the American Go Association still describes as <em>quite
simply the best and fastest teaching method ever devised, at least in
English</em>. Nowadays not a game commentary or replay goes by without
analysis using terminology I invented. It’s a strange feeling, changing
the world. I imagine Google staff has that same feeling. Google has
shifted the world’s conceptual landscape, too. Google search is
completely integrated into my way of life and didn’t exist before. I
don’t buy piles of technical books. Heck, I don’t even bother to
remember details of programming languages I use. I just <em>Google</em>
something as I need it. I am crippled without the Internet. And I give
thanks to the gods that I don’t have to say <em>give me a moment to
“bing” that</em>.</p>
<p>My Go program was the first successful one. It could give a 9-stone
handicap to a beginner and expect to win. That’s like queen’s odds in
chess. At the time, all other Go programs could lose playing even to
someone who had just been taught the rules. My boss and I published a
bunch of seminal articles on computer Go. Eventually I released a Go
program on the IBM-PC and sold it in Japan. The Japanese Fifth
Generation Computer project spent millions trying to defeat my program
and failed.</p>
<p>But AI has traditionally been won by brute force. Computer chess is
the prototypical example, wherein search-based approaches trumped
knowledge-based ones. For a while, knowledge-based approaches in Go such
as mine held the upper hand, but I left the field and today monte-carlo
search-based Go programs dominate.</p>
<p>Brute force today includes high speed searches on massive databases.
You guys. Machine translation, for example, used to be the domain of
knowledge-based approaches. Now Google has led us to data-based
translation. But massive data still needs a clever insight to use it or
a clever algorithm to process it. Predicting flu season by keyword
search trends is a clever use of data. But despite your advances in
machine translation, I still have trouble making sense of Japanese
web-sites you translate.</p>
<h2 id="route-planning">Route Planning</h2>
<p>When I worked on real-time vehicle AI for DARPA in the 80’s, I did
route-planning for tank platoon leaders. I talked to them, read the
military manuals, even went inside an Abrams tank at Fort Knox. I
learned to think like a tank platoon leader. The standard computer
algorithm of the day for route planning was a flood-fill, which
generated perfect answers. Even today the standard algorithm in video
games is A* which is just a cleverly guided flood fill. Back then, the
flood fill took hours on big machines and thus was completely useless in
the field. I used a different perspective to make a program that took
seconds instead of hours and did better than humans (within 85% of
perfect). I tried to improve upon how the platoon leaders actually
planned routes.</p>
<p>I used expert-system-controlled ray-tracing and treated parts of
terrain as optical surfaces. The system looked at a ray from start to
goal, detected the forest obstruction in the way, determined the rays
that would be needed to clear the forest on each side, and then recursed
on each of those rays. And when the terrain was not obstructive, merely
faster or slower, my system approximated the terrain as a series of
lenses and computed the optimal path light would take through it using
Snell’s law. It would latch onto roads and angle thru swamps perfectly.
Nowadays, of course, I would just go to Google maps and ask it to plot
me a route.</p>
<h2 id="planners">Planners</h2>
<p>In 2004 Radical Entertainment, a games company, contacted me and
asked me to tell them where to invest time on next-generation AI
algorithms. I researched that and told them that academic planning
technology had gotten really interesting, but that they were written
completely wrong for video-games and should be rebuilt. I had no
experience with planning technology, but they asked me to design and
build such a system, which I did. It was called HIPE. At a planning
competition in 2000, the best and fastest commercial planner solved a
500 block stacking problem in 974 moves. For my first delivery milestone
on the same hardware, HIPE solved the problem 300 times faster, found a
solution requiring 5 fewer moves, and was built in keeping with
video-games’ demanding memory and CPU requirements. Shortly after HIPE
was complete, the company got bought by a larger game company, who shut
down the research section and HIPE disappeared.</p>
<h2 id="cellphones">Cellphones</h2>
<p>Then I worked for LimeLife, a cell-phone application company in a
fragmented market of different phone screen sizes and ideosyncratic OS
implementions. It was a coding mess building anything. It was sort of
like the Android market today.</p>
<p>When I was hired, of course, I knew nothing of cell phones or the
languages for programming them. I worked through my first project using
J2ME, a cut down JAVA for mobile. Size was always a critical problem
back in the days of a 128k RAM limit for code and data. For my second
project, the company was trying to win a really big customer- the
publisher of InStyle and People magazines. I was warned of a meeting a
month ahead wherein Limelife would learn what the product should be
like. They only knew they would need a rapid prototype and that probably
the product would have to be customizable somehow via download. LimeLife
didn’t have those capabilities.</p>
<p>I concluded we needed a language designed specifically for mobile,
not ones carved from other languages. I designed FLIRT, a combination
scripting and automatic screen layout language. You could call it a
browser language for mobile. Its programs were half the size of J2ME
programs and it could be downloaded and/or updated on the fly. FLIRT
programs ran instantly on all phones. An initial cut of FLIRT was
running in time to build the InStyle prototype, and I was just about
able, in real time, to keep up with modifications the artist and
designer kept providing as revised prototype sketches. Limelife won the
contract and the InStyle product I programmed won the “best mobile
strategy” award from the Magazine Publishers Association for 2008.</p>
<p>But LimeLife collapsed. Going into a financial tailspin has happened
with a lot of companies I’ve worked for. I don’t think I am responsible.
But if they hadn’t gone under, I’d still be working for them, so I think
it must be fate’s way of telling me to move on.</p>
<h2 id="chatbots">Chatbots</h2>
<p>I got into chatbots as a complete newbie back in 2008. And I give two
things credit for winning the Loebner in 2010 and 2011. First, my wife
found England’s winters too cold. And second, Google blocked me from
using it.</p>
<p>We had moved to England for family reasons, but with the onset of the
first winter, my wife found it too cold and wanted somewhere warmer. So
I contacted a friend in Hawaii, to try to sell him a game I had lying
around. He had just sold his cell-phone application company, but had
founded a new company named Avatar Reality to build a virtual world
called Blue Mars, a gorgeous high-end place designed to wipe-out Second
Life. He wanted people to have persistent avatars that moved around like
the user even when the user was offline. So he wanted me to do that. But
then it turned out they didn’t have functioning avatars yet, so I
couldn’t work on that task. They weren’t ready to hire me. We moved to
Hawaii anyway. I then suggested that if the avatars were going to
pretend to be users, they should chat like them too. After a bunch of
research on the web to learn about chatbots, I made a proposal and they
agreed. Thus began my new-found passion for natural language
processing.</p>
<p>There are two kinds of chatbots at present. The hand-scripted ones,
like A.L.I.C.E., written in AIML (aka AI Markup Language), and the
data-mining kind that memorizes everything ever said to it, epitomized
by Cleverbot. Cleverbot is the brute-force approach. It has about 50
million lines of chat and automatically acquires more.</p>
<p>I proposed something like Cleverbot, to memorize everything a
specific user said in chat. But since users wouldn’t talk about
everything, I thought that when necessary it should send out Google
queries to find responses that would be appropriate. It’s not so much
looking up facts in Google, but finding out how people have completed
the answer to a question. If asked “How often do you swim”… it would go
Google for sentences of the form “I often swim …”.</p>
<p>After a few months, the system seemed to work. But then Google
started blocking my queries. I created a round-robin system to go across
a dozen different search engines, but eventually decided to scrap the
whole approach. This forced me into the hand-scripted method, creating
my own chatbot language because AIML was too weak for what I wanted to
do. And ultimately that allowed me to enter the Loebner’s, which doesn’t
allow Internet connections. So I thank you for that.</p>
<p>I still think that the Cleverbot approach will eventually follow in
the AI tradition of brute force winning out, but it came in 3 rd last
year and didn’t qualify this year. Data is not enough. You still need a
clever algorithm to exploit that data. That’s something Cleverbot seems
to lack, despite its name.</p>
<p>The Loebner’s has long been dominated by regular entrants. Last year
my competitors were multiple-year winners. Cleverbot, with 50 million
responses, lost to ALICE, with a mere 120,000 rules. But Suzette, with
only 15,000 rules, fooled a human judge, defeating ALICE.</p>
<p>Because that engine and chatbot were owned by Avatar Reality, I
couldn’t do anything commercial with it. So about 5 months before the
2010 contest, I decided to start over from scratch. Suzette was going to
become a dead end. I would have to rewrite my 50,000 lines of engine
code and my 15,000 rules.</p>
<p>Due to really bad timing, I started coding my new engine while
starting a new job at Telltale Games, and signing a contract with a
Japanese company to build them an ESL bot in what would become my new
engine. I was significantly overloaded until April of this year, so only
had a few months to actually build my new chatbot, Rosette.</p>
<p>Rosette is only 2/3 the size of Suzette. And this year the tech savvy
judges took great pains not to suffer the embarrassment of misjudgment
that happened last year. Still, Rosette came in first in the qualifiers
and was the top pick of all four judges in the actual contest for most
human computer. What is my secret?</p>
<h2 id="chat-technology">Chat Technology</h2>
<p>OK. Now we leave history and delve into the underlying technology. As
a human I was already a domain expert in conversation, so I did what I
always do. I researched all the chatbot stuff I could, including AIML, a
sitecalled Personality Forge, a videogame called FAÇADE, Jabberwock, a
winning chatbot from early 2000’s, etc.</p>
<p>They all had different interesting bits but, as usual, I found I had
serious complaints. It’s those complaints that motivated my design for
yet another application-specific scripting language. I also researched
knowledge representation and inferencing, eventually picking CMU’s Scone
Project as my rough model.</p>
<p>All hand-scripted chatbots consist of a collection of rules- the
classic expert system of IF-THEN rules. A rule consists of a pattern
which is matched against the input. The pattern of a rule usually
consists of words and/or wildcards that can match an arbitrary sequence
of words.</p>
<p>AIML I describe AIML for a moment for a couple of reasons. First, it
is the dominant open source platform. Second, ALICE is written in AIML
and she is perennially one of the top chatbots. AIML is based on XML. In
AIML, the pattern must precisely cover all input. If the pattern
matches, the output code is executed. The output side can perform
various simple computations, and output specific words or wildcards that
were matched to one or more words. When the output side of the initially
matching rule is complete, the response is done. AIML is elegant in its
simplicity. The primary clever thing AIML supports is generating a new
input sentence and submitting it to itself for further computation,
sometimes submitting multiple sentences and then combining their output.
All of AIML’s power comes from this recursive ability. Here is a simple
AIML rule that responds precisely to <em>Do you love me?</em></p>
<pre><code>&lt;category&gt;
&lt;pattern&gt; DO YOU LOVE ME &lt;/pattern&gt;
&lt;template&gt;I love you &lt;/template&gt;
&lt;/category&gt;</code></pre>
<p><em>Category</em> is AIML’s word for a rule. <em>Pattern</em> is what
to match against. <em>Template</em> is what do execute or say in
response. AIML and other chatbot languages discard all punctuation and
AIML is case insensitive (input normalizes to upper case).</p>
<pre><code>&lt;category&gt;&lt;pattern&gt; * YOU LOVE ME * &lt;/pattern&gt;&lt;template&gt;I love you &lt;/template&gt; &lt;/category&gt;</code></pre>
<p>The above matches <em>Do you love me</em> always but not <em>Will you
love me</em>, because a wildcard must match at least one word and the
trailing wildcard doesn’t.</p>
<p>To handle all forms of “you love me” in sequence, but not
consecutively (e.g. <em>Will you really love only me tonight</em>),
would require 16 AIML categories using various combinations of the *
wildcard.</p>
<p>Now consider rejoinders. After you script a chatbot’s output you can
sometimes guess the human’s response, and if you have a clever rejoinder
ready, your bot looks really good. If the human asks <em>do you love
me</em> and your bot replies <em>I love you</em>, maybe the human will
then reply <em>You are just saying that</em>. Glib counters like <em>No,
I really mean it</em> go a long way to creating the illusion of
understanding. AIML manages rejoinders by adding an extra pattern to a
category, called that:</p>
<pre><code>&lt;category&gt;
&lt;pattern&gt; YOU ARE JUST SAYING THAT&lt;/pattern&gt;
&lt;that&gt; I LOVE YOU &lt;/that&gt;
&lt;template&gt;No, I mean it&lt;/template&gt;
&lt;/category&gt;</code></pre>
<p>If the last thing the bot said was “I love you” and the human says
“you are just saying that”, this matches. Because <em>that</em> is a
pattern, it can include wildcards and be made to match the output of
multiple rules. But that capability is overkill. One generally only ties
a rejoinder to a specific rule, and so one just restates the output it
matches.</p>
<p>Basic point — AIML is incredibly wordy. Because of that you can’t
glance at AIML code and see what it does. You have to read it. AIML
damages itself by being based on XML. It is catering to the
computer-science machine view, instead of the human authoring view. One
can build tools to try to hide the XML. But if you are going to hide it,
why have it in the first place? And that’s just for input patterns.</p>
<p>On the output side, you can also do many esoterically wild things
using recursive input, but one thing is certain, what is happening will
become confusing and obfuscated because it will cross through many
categories before being fully processed. It becomes harder and harder to
keep in your head how a large chatbot works when its guts are spilled
out across many different categories in probably many different
files.</p>
<p>Enough of AIML.</p>
<h2 id="chatscript">ChatScript</h2>
<p>ChatScript is similar in that it is a collection of IF-THEN rules,
which match patterns against the input and executes output code when the
pattern matches. So what makes ChatScript better?</p>
<p>First, it is much cleaner to read and write. A chatbot needs a lot of
material. Hand-authored text takes time and the more characters you have
to type, the longer it takes to author. In addition to merely writing
lots of material, serious chatbots with a large number of rules become
harder to author because it becomes hard to track what you do and do not
have in it and it becomes harder to add new material without impacting
access to the older material.</p>
<p>Here’s simple ChatScript, comparable to the AIML you saw:</p>
<pre><code>?: (you * love * me) I love you.
  
  a: (you are just saying that) No, I mean it.
    
    b: (no) You think I love someone else?</code></pre>
<p>The <code>?:</code> is the rule type. ChatScript strips off only the
ending punctuation, but it uses that punctuation to guide which rules
should be tried.</p>
<p><code>s:</code> rules only react to statements. <code>?:</code> rules
only react to questions. <code>u:</code> rules react to the union of
both. ChatScript can detect questions either because a question mark was
used, or because the sentence is structured as a question.</p>
<p>The pattern is encased in <code>( )</code> and the output occurs
after the closing <code>)</code> .</p>
<p>ChatScript doesn’t have to match all words of the input. And
ChatScript’s <code>*</code> wildcard matches 0 or more words instead of
1 or more. So one ChatScript rule can match everything that requires 16
AIML categories.</p>
<p>ChatScript rejoinders occur visually immediately after the
corresponding rule and get tested only on user input immediately after
that rule fired. You can have multiple levels of rejoinders, marked by
increasing letters of the alphabet. The <code>a:</code> is a level 1
rejoinder. The <code>b:</code> is a level two rejoinder for responses to
the <code>a:</code>.</p>
<p>OK. Formatting differences do not a winning chatbot make, but it’s a
start.</p>
<h2 id="chatscript-topics">ChatScript Topics</h2>
<p>ChatScript requires that you organize rules into collections of
topics. AIML has a topic concept, but the mechanism for it is so hard to
use, no one does, not even ALICE. Being able to organize, manage, and
automatically test large quantities of rules is an important trait for
any expert system (or any large program for that matter). AIML offers no
support for this. ChatScript does.</p>
<p>A Chatscript <em>topic</em> is a name, a collection of keywords, and
a collection of rules.</p>
<p>Topics allow one to encapsulate rules related to it and independently
author sections of the chatbot. The system doesn’t have to consult rules
in topics unless it is currently in that topic, has been told to try
that topic, or the sentence has one of the topic keywords in it,
suggesting that maybe this topic is relevant.</p>
<p>The mini-topic below illustrates most of ChatScript’s syntax and will
be explained in detail. I am going to cover a lot of capabilities (and
gloss over a lot of subtleties) in explaining it.</p>
<pre><code>concept: ~baseball_team [ Giants &quot;Red Sox&quot; Yankees ]

topic: ~baseball [ baseball~1 ~baseball_team &quot;home run&quot; runs base~n ]

t: ( !$histeam ) What is your favorite baseball team?
   a: ( not ) You don&#39;t like baseball? How un-American. 
   a: ( Giants ) ^reuse(GIANTS)
   a: ( ~baseball_team ) They&#39;re OK, I suppose.

t: GIANTS ( !$histeam ) I like our home team, the Giants.

#! I really love baseball
#! I enjoy softball
s: ( !not I *~2 ~love *~2 baseball~1 ) So do many Americans.

#! I like the Yankees.
s: ( !Giant I * ~like * _ baseball_team ) I&#39;m a Giants fan. $histeam = _0

#! What team do you most like?
#! Your favorite team?
#! Do you have a most special baseball team?
?: ( &lt;&lt; you ~favorite team &gt;&gt; )  ^reuse(baseball.giants)

#! I hit 46 home runs last year.
#! I had three thousand and twenty home runs this season
s: ( I [hit have] ~number&gt;40 * home run ) That&#39;s impressive.</code></pre>
<p>In addition to the <em>responders</em> ( <code>s:</code>
<code>u:</code> <code>?:</code> ) and <em>rejoinders</em> (
<code>a:</code> <code>b:</code> etc ), topics have a type of rule called
a <em>gambit</em> ( <code>t:</code> ) . It’s something the chatbot can
say when it has control. Even if the system cannot find a direct
response to your input, if your input suggests we are talking about
baseball, the chatbot can offer you a relevant gambit. Or the bot can
initiate a topic and say a gambit.</p>
<p><em>Gambits</em> allow the chatbot to tell a story in the topic. If
the user metaphorically nods his head in acknowledgement after a gambit,
the system is free to issue the next one in sequence. If the user asks a
question or makes his own statement, the system can try rejoinders or
other responders to reply.</p>
<p>One of the implied rules of a conversation is maintaining a balance
of intimacy. If I ask you a question, I am expected to share my answer
to it as well. So I often author a topic in a style of gambits asking a
question and then volunteering the chatbot’s answer, as is seen in the
baseball topic.</p>
<p>Gambits do not require patterns, but they can have them. Typically
this is done to test conditions unrelated to the user’s input. In the
gambits above, we want to volunteer the question and our own response
ONLY if the user has not already told us what his favorite team is, that
is, only if the variable $histeam is undefined. It will be set by a
responder previously if it detected the user telling us his favorite
team.</p>
<p>Rules can have labels, and be the target of other rules. The label is
after the rule type and before the pattern component. reuse(GIANTS)
tells the system to execute the output of the labeled rule. This saves
having to rewrite that output multiple times, and supports avoiding
repetition as described later.</p>
<p><code>#</code> is the comment character. <code>#!</code> is a special
comment that says: here is a sample input for the immediately following
rule. Not only does this help the author read what his rules cover, but
the system can be run to verify that all such commented rules would
actually match if given the corresponding input (would you believe that
sometimes I actually write a faulty pattern for what I intend?). And
verification can tell you if the rule can be found if you aren’t
currently in that topic or if a rule is masked by an earlier rule in the
same topic.</p>
<h2 id="chatscript-generalization">ChatScript Generalization</h2>
<p>ChatScript allows you to generalize words. This is gives you the
power to match related words and thus write compact scripts.</p>
<p>You can declare a set of words as a concept and then use that concept
name in places where you would use an ordinary word. You see above, the
concept of <code>~baseball_team</code> defined. You can then use a
concept, e.g., in a rejoinder like: <code>a: (~baseball_team)</code> and
it matches any baseball team’s name in the list. You can even use
phrases as keywords, like “home run”, and they will behave in a pattern
like a single word.</p>
<p>Also when you use a word, you can annotate it to restrict its part of
speech. Hence, <code>base~n</code> means base is a keyword of
<code>~baseball</code> if used as a noun in input but not if used as a
verb.</p>
<p>ChatScript uses <a href="https://wordnet.princeton.edu/">WordNet</a>,
a computerized dictionary, with the WordNet ontology (a collie is a dog
is a canine is a mammal is a being) and you can refer to a WordNet
meaning in your patterns, which automatically stands for any refining
word below it in the WordNet hierarchy, providing a bunch of instant
sets of words. In the topic definition, <code>baseball~1</code> is a
reference to the Wordnet definition one of baseball, which also covers
lower level words hardball and softball. That is a small use, but a
reference like <code>plant~2</code> refer to thousands of plants (
<code>plant~1</code> refers to industrial plants).</p>
<p>ChatScript also generalizes words automatically, simultaneously
matching both the original and its canonical form of the input against
your keywords. This means you can write things that are insensitive to
case, plurality, determiner, degree, and tense.</p>
<p>A <code>~baseball</code> rule uses <code>~number</code> (a predefined
concept of all numbers) and matches all of its test inputs. For this
pattern, however you write a number, in digits or in words, the digit
form is the canonical form. You can even put tests in the pattern.</p>
<p>The baseball topic uses <em>runs</em>, which is not its canonical
form, which means it will not be triggered by <em>ran</em> or
<em>run</em> or <em>running</em>. You can also suppress canonical
matching of a word merely by putting a single-quote in front of it.</p>
<p>Topics have keywords so the ChatScript engine can automatically find
the most relevant topic for an input sentence by looking at the number
of matching keywords it has and how big the keywords are. The system
will try rules in the most likely topic first, and if they all fail, it
will try lesser matching topics. Topics that don’t match don’t get tried
unless you explicitly tell the system to try them (you can completely
control how processing is done).</p>
<p>Topics have <em>keywords</em> so the ChatScript engine can
automatically find the most relevant topic for an input sentence by
looking at the number of matching keywords it has and how big the
keywords are. The system will try rules in the most likely topic first,
and if they all fail, it will try lesser matching topics. Topics that
don’t match don’t get tried unless you explicitly tell the system to try
them (you can completely control how processing is done).</p>
<p>A concept name always begins with a <code>~</code> and so does a
topic name. Topics are also concepts and the topic name stands for all
its keywords. Sometimes there are idiomatic sentences that have no
useful keywords in them. <em>What do you do?</em> for example. Rosette
handles these by always first calling a topic that tests for idioms,
which marks things so that the correct topic will get attention
anyway.</p>
<p>Having topics means the system can prioritize by examining the
current topic first. Or return to recent topics.</p>
<p>Via generalization, a single ChatScript rule may do the work of
hundreds or thousands of AIML rules. When I say that ALICE has 120,000
rules and Suzette had only 15,000, that comparison is meaningless,
except that it indicates it took me a lot less time to write Suzette’s
rules than it took them to write ALICE’s.</p>
<h2 id="chatscript-pattern-matching-specificity">ChatScript pattern
matching specificity</h2>
<p>AIML patterns are simplistic and imprecise. AIML does a pattern match
on words. I characterize ChatScript as doing a pattern match on meaning.
Generalization is an important part of this. So are wildcards, but
AIML’s are unrestricted.</p>
<p>Errors in pattern matching come in two flavors. <em>False
negatives</em> (failing to match what you want) and <em>false
positives</em> (matching what you don’t want). It is easy to match
things. This AIML wildcard <code>*</code> can match anything (just not
nothing). The trick is to avoid matching the wrong things, which AIML
doesn’t do well.</p>
<p>Since you don’t want to write a rule for every sentence you could
encounter, AIML generalizes by adding wildcards,
<code>I * love * you *</code>. This instantly goes way too far. It can
match <em>I love filet mignon, what you would call steak</em> and <em>I
would rather die than love you ever</em></p>
<p>ChatScript’s wildcards can be limited to specific word counts, or
limited to within small ranges. <code>*~n</code> means 0 or more words
up to n inclusive. This means you can write patterns that don’t go off
on wild tangents</p>
<pre><code>#! I really love baseball
s: (!not I *~2 love *~2 baseball)</code></pre>
<p>The <code>s:</code> rule matches a meaning wherein the user says they
love baseball. For me, <code>*~2</code> is a common idiom. It allows a
determiner + adjective, or a pair of adverbs to creep in, but not much
more.</p>
<p>AIML automatically captures the words its wildcard matches. In
ChatScript, you can request such a capture by placing an <code>_</code>
before it. Thus <code>s: ( _ * )</code> would memorize the entire user
sentence. During output, you can refer to the capture by saying
<code>_0</code> or <code>_1</code> or whichever wildcard you want when
you had multiple. Typically one rarely has more than 3 captures in a
pattern, though you may well have more wildcards. In the baseball topic,
if the user says <em>I like the Yankees</em>, the responder for that
captures <em>Yankees</em> and stores it on the global variable $histeam.
We might use that in some gambit later to inquire more about his team.
It would help prove the chatbot understood what he said.</p>
<p>An AIML pattern is heavily dependent upon word order. ChatScript can
write rules that don’t care about the order.
<code>&lt;&lt; you ~favorite team  &gt;&gt;</code> means all of the
given terms, but in any order. The convention, by the way to match a
word aligned at the start or end of a sentence is to use the
<code>&lt;</code> or <code>&gt;</code> markers, as in
<code>(&lt; do you love me &gt; )</code>, which is functionally exactly
the same as the AIML pattern I first showed you.</p>
<p>In Art, people talk about the importance of negative space. Negative
space, the absence of words, is important in meaning. “I do not love
baseball” is hugely different from “I do love baseball”. Simple
wildcards hide the <em>not</em>. ChatScript allows you to confirm the
non-existence of it. <code>!not</code> tests that the word <em>not</em>
does not appear anywhere after where we are now.</p>
<p>Matching sets of words, combined with restricted wildcards and using
negative space, enables one to write precise patterns about a specific
meaning.</p>
<p>In case you are thinking - why not just parse the input - I do that
too (another thing that chatbots don’t tend to do- in part for
performance reasons), and you can write patterns that depend on the
parse. But chatbots cannot count on Wall Street Journal style sentences
being passed in. Lots of input is not very parseable - such as bad
mangled English, texting, and short phrases. Just like some people type
in all lower case and others in upper case.</p>
<p>And the 97% accuracy rate of most statistical Part-of-Speech-taggers
trained on the Wall Street Journal means a lot of parse errors in casual
chat (the word <em>like</em> is statistically a conjunction for WSJ
whereas in chat it’s usually a verb). As you might expect, I’ve been
working on my own tagger and. It’s rule-based with statistics for tie-
breaking when rules aren’t enough. It currently runs about 30 times
faster than the Stanford parser and I’m aiming for 99.5% accuracy (but
I’m not there yet).</p>
<h2 id="ontology">Ontology</h2>
<p>You already know that ChatScript supports concepts. It comes with
some 1400 predefined concepts, you can define your own, and it has
WordNet’s ontology. Their noun ontology is often good, but other times
it is not what I would want, and their non-noun ontologies are poor. I
looked at SUMO’s ontology (Suggested Upper Merged Ontology), but it,
too, I find often useless. It shouldn’t come as a surprise that I have
my own perspective on ontology (everyone does), and have created my own
ontologies for nouns, verbs, adjectives, and adverbs. My ontologies are
oriented for use with a chatbot to generalize meaning. My viewpoint is
based on classifying the primary function of a word.</p>
<p>Take the verbs “paint” and “dirty” and “sculpt”. In WordNet, the
hierarchies are:</p>
<pre><code>paint =&gt; cover
dirty =&gt; change
sculpt =&gt; mould          =&gt; create</code></pre>
<p>In SUMO, the hierarchies are:</p>
<pre><code>paint =&gt; coloring        =&gt; surface change  =&gt; internal change
dirty =&gt; combining
sculpt =&gt; shape change                      =&gt; internal change</code></pre>
<p>Those hierarchies are useless to me- the words have nothing in
common. To me, the words are all related. I view them as primarily about
aesthetics. The ChatScript hierarchy is:</p>
<pre><code>paint =&gt; colorize               =&gt; alter aesthetics better =&gt; alter aesthetics =&gt; affect objects
dirty =&gt; alter aesthetics worse =&gt; alter aesthetics                            =&gt; affect objects
sculpt =&gt; cutArt                =&gt; alter aesthetics better =&gt; alter aesthetics =&gt; affect objects</code></pre>
<h2 id="chatscript-directly-supports-chat-itself.">ChatScript directly
supports chat itself.</h2>
<p>ChatScript supports “the word”. It has a dictionary with parts of
speech and word attribute knowledge (it knows common male first names
etc). It does spell-correction, part-of-speech-tagging, parsing.</p>
<p>ChatScript has topics with gambits, directly enabling telling a story
and maintaining a balance of shared intimacy. And topics enable the
system to order collections of rules by relevance to the input.</p>
<p>Chat is also self-extinguishing. You don’t want to repeat yourself.
If you ask me what my job is and I tell you I work for the phone
company, I shouldn’t later volunteer that same information. By default
ChatScript both marks rules when they get used, to avoid using them
again, and looks up its current output to see if it has already said it
recently. In either case, the current rule would fail and the system
would move on to find another matching rule.</p>
<p>This means that I often write rules that share data using the
<code>^reuse()</code> function. If the system gets asked what is your
favorite baseball team, the matching rule says reuse the gambit labeled
Giants. That rule will output the answer and mark itself as having been
used. This means the system will no longer volunteer it on its own,
which would be redundant.</p>
<p>In addition, because you can test variables in the pattern side, you
can avoid asking the user questions which he already volunteered the
answer for. You see that with the first baseball gambit. AIML only
matches input with its patterns. It cannot test variables.</p>
<h2
id="chatscript-can-represent-and-manipulate-arbitrary-data">ChatScript
can represent and manipulate arbitrary data</h2>
<p>ChatScript supports facts, represented as triples. You can build
tables of data and combine facts into arbitrary graphs. Concepts are
represented using facts, as is WordNet’s ontology. ChatScript has a
programmable query function to go search and inference your facts. If
you ask <em>what is the capital of France</em>, Rosette does not have a
rule that spews forth a canned response for exactly that. Instead the
script has a rule to manage the capital city of anywhere. It tells her
to search for cities in the named place, looking for ones that are also
capitals.</p>
<p>For what was probably the most difficult Loebner qualifier
question:</p>
<p><em>Dave is older than Steve but Steve is older than Jane. Who is
youngest, Steve or Jane?</em></p>
<p>Rosette was the only entrant to try, and got the question right,
replying: <em>Jane is youngest</em>.</p>
<p>Here are the other Loebner finalists’ responses for comparison:</p>
<ol type="1">
<li><em>I can’t tell you because I don’t know what these are: Steve,
Jane.</em></li>
<li><em>You just told me something interesting about Dave and Steve but
Steve is older than Jane. why are you asking me?</em></li>
<li><em>You’re right. You don’t know who youngest Steve or Jane is? You
should know.</em></li>
</ol>
<p>And then for good measure, here are ALICE and Cleverbot’s
answers.</p>
<ol type="1">
<li><em>And older than Steve but Steve is older than Jane is Dave. No
one that I have talked to.</em> (ALICE)</li>
<li><em>Ok so your name is Ed.</em> (CleverBot)</li>
</ol>
<p>Was Rosette’s reply a triumph of understanding meaning? She could
have just picked at random from the given two choices and gotten lucky.
Even that would have required some understanding, to not react to the
first sentence and to pick a choice from the second. But she was far
cleverer than that.</p>
<p>Rosette used a rule to detect in the first sentence that you were
offering comparisons of people by adjective. She ran the same rule over
that sentence several times to swallow all of the information it
contained. She built facts ordering them by size, keeping a canonical
orientation.</p>
<pre><code>(Dave old Steve)
(Steve old Jane)</code></pre>
<p>Had you said <em>Dave is older than Steve. Jane is younger than
Steve</em>, Rosette would have generated the same internal set of
canonical facts across two sentences, compensating for the flip of
adjective viewpoint from older to younger. Word opposites are also
stored as facts she can query.</p>
<p>Then when the question came, Rosette determined what was being asked
and which way it was being asked compared to how the facts were stored.
Younger is the opposite of how she had stored the facts so she retrieved
the data compensating for that and replied: <em>Jane is
youngest.</em></p>
<p>It took just 6 rules dedicated to detecting various sentence formats
providing the adjective comparison data and 3 rules for different kinds
of questions that might be asked about that data. Those 3 rules covered
being asked the following kinds of questions. Bear in mind that these
example questions from my script are about height comparisons, but in
the Loebner’s the questions and data were about age. It’s all the same
script using plug &amp; play adjectives.</p>
<pre><code>#! Who is tallest
#! Of Tom, Mary, and Sarah, who is the shortest
#! Who is the least tall
#! Who is taller than Harry?
#! Name someone shorter than Harry
#! Who is taller, Tom or Harry?
#! Who is the taller of Mary and Harry
#! Of Tom and Harry, who is least tall?</code></pre>
<p>Rosette similarly correctly answered: <em>Which is larger, an ant or
an anteater?</em> by inferencing among sets of sizes of things, deciding
that ants were in insects, anteaters were in animals, and animals were
bigger than insects. There are two normal rules dedicated to that kind
of question and 8 rules for trick questions like <em>Which is larger, a
huge ant or a tiny ant</em>. ALICE was the only other program to even
attempt to answer the ant vs the anteater question. My bet is she got it
right by guessing.</p>
<p>The previous year Suzette got 11 of 20 qualifier questions correct.
This year, Rosette got 16 of the 20 different but similar questions
correct, compared to 10-11 for her best competitors. 3 of Rosette’s 4
errors were pattern generalization errors I made in my haste. She could
have answered the questions correctly, but matched wrong rules. She
could not have answered <em>what letter comes after T</em> because I had
failed to give her instruction about the alphabet and how to manipulate
it. Obviously since corrected.</p>
<h2 id="chatscript-supports-full-scripting-output">ChatScript supports
full scripting output</h2>
<p>AIML has limited output capabilities, but some versions allow you to
use JavaScript as well. ChatScript is a complete scripting language. You
can write the output, as AIML allows, and you can do loops, arithmetic,
assignment, if conditions, etc. You can declare and call functions. You
can do graph queries and you can invoke topics. You can even submit
input to the engine as AIML does, which is what happens for pronoun
resolution - Rosette rewrites the sentence replacing the pronoun, then
cancels the current one and submits the new one.</p>
<h2 id="chatscript-supports-introspection">ChatScript supports
introspection</h2>
<p>The control code is just another topic, which you can script to do
anything you want. The system will call a topic you name before the
input, so you can perform initializations. Another topic is called for
each user sentence in the input (if the input is multiple sentences).
And a final topic will get called after all sentences, to handle any
post-processing you want.</p>
<p>The engine can detect automatically repetition. It parses both input
and output, so it supports automatic pronoun resolution , and script can
compute what it “expects” if the user is to reply reasonably. If, for
example, Rosette asks you <em>how much xxx</em>, then the
post-processing topic determines that she asked that kind of question
and notes she is expecting a quantity kind of answer. Which it tests for
on the next user input to see if expectations are met. The control topic
makes decisions about whether you “nodded” your head, asked for a change
of topic, answered the question appropriately, etc.</p>
<h2 id="chatscript-summary">ChatScript Summary</h2>
<p>This completes the essentials of ChatScript. Using patterns which
combine fine-granularity control over wildcards with broad
generalization using ontology and the handling of negative space, you
can easily write script to detect inputs with specific meanings. Using
facts and customized inferencing you can manipulate pre- existing or
built-on-the-fly collections of data. The topic structure and visually
sparse layout allows you to quickly and easily author and organize
independent areas of knowledge. And the ability to write your own
control structures and introspect what the engine did allows you to
craft any personality you want and address handling social
conversational clues, transitional sentences, and other nice-ities of
conversation.</p>
<p>Using ChatScript, a hastily crafted bot named Rosette qualified first
and then won this year’s Loebner’s by unanimous judgment.</p>
<h2 id="fairytales">FairyTales</h2>
<p>Telltale Games hired me in part for my natural language skills. When
I joined, I was told that designers had always dreamed of doing a
story-telling product. You would feed it simple sentences and it would
act out what you said. It was merely a wish, but it seemed like a
perfect project for me. I would get to explore issues in meaning from a
different perspective (you know me and perspectives) and I had a wealth
of chatbot experience and ontology data I had built for Suzette.</p>
<p>So, using ChatScript, in a week, I cobbled up a fixed demo where you
could create sentences of “subject verb object” using fairy tale
characters and a small number of verbs to do something with or to
another character. The output was a text description of the result,
because I had no way to make it visual. The verdict was “this is cool,
now make it visual using our tool”.</p>
<p>Thus began a background project to do that. Telltales’s goal is to
expand its technology while potentially making a product. For me, it’s
an opportunity to look at computerizing meaning using extremely simple
sentences instead of the complexity of full user input as seen by a
chatbot.</p>
<p>The research parallel is the game Scribblenauts, a recent
side-scroller puzzle game where a character named Maxwell has to
overcome obstacles to grab a “starite”. You control his movement and you
can summon into the world one or more of some 20,000 nouns. Each has
inherent behaviors and you have to pick nouns that will help your quest.
Find a bunch of bees in your way? Summon a beekeeper, or honey, or a
fire-breathing dragon, or an atomic bomb (some choices have consequences
of use that may not work well for you). Scribblenauts doesn’t address
verbs, except that you can “use”, “mount”, “attach” and “detach” things
through the interface. I’d been jealous of Scribblenauts when it came
out, wishing I could have built such a clever little world. This was my
chance. I could be the first to handle complete control using verbs. No
mouse, just pure sentence input.</p>
<p>I started by designing for the worst case: all nouns and all verbs.
We’ll have to limit it somehow later because we won’t be able to create
all the art assets. You get to pick one of the game characters as the
subject, any verbs, and some object which can either be a game character
or a concrete noun. Verbs are always done in present tense base form.
There is no game design yet, but imagine the following prototype
scenario:</p>
<p>It’s a fairy tale, with the usual cast of characters available-
prince, king, princess, wizard, dragon. There is a princess in a castle.
She wants to get married. You must achieve that for her. Here is what
you type:</p>
<ol type="1">
<li><em>princess marry prince</em>. The system says- She will only marry
a heroic prince.</li>
<li><em>prince kill dragon</em> - Dragon arrives. They fight. The
unarmed and unarmored prince dies.</li>
<li><em>prince take shield</em> - a new prince arrives and grabs a
shield.</li>
<li><em>prince take sword</em> - he grabs a sword</li>
<li><em>prince kill dragon</em> - They fight. This time the dragon
dies</li>
<li><em>prince marry princess</em> - The system says- She will not marry
someone evil. Turns out the new prince is not as good as the old
one.</li>
<li><em>princess sanctify prince</em> - The system says- You lack a
crucifix.</li>
<li><em>princess take crucifix</em> - The princess takes a crucifix</li>
<li><em>princess sanctify prince</em> - The prince loses all his evil
nature.</li>
<li><em>princess marry prince</em> - You win.</li>
</ol>
<p>The ongoing work on this project is Telltale proprietary, so I can’t
describe solutions. I do have permission to share the issues in
understanding meaning that have arisen. My solution, of course, is to
create another application-specific scripting language called
WorldScript, to allow designers and content programmers to define a
computerized handling of words with as little typing as possible.</p>
<h3 id="easy-case">Easy Case</h3>
<p><em>king hit princess</em></p>
<p>This is straight-forward and simple. A king arrives at the castle,
walks over to the princess, hits her. She suffers damage, dislikes the
king, and either retaliates or flees.</p>
<h3 id="multiple-interpretations">Multiple Interpretations</h3>
<p>Issues with words of multiple interpretations crop up
immediately.</p>
<p><em>king take xxx (pill, breath, break, purse, bus)</em></p>
<p>How does one handle them? The meanings of take are idiomatically
different depending on the object. Just using take to mean “get physical
control over” would be acceptable. But I actually do try to use the
idiomatic interpretation.</p>
<p><em>king take bat</em> - is it a baseball bat or a flying bat?</p>
<p>The simple answer for multiple meanings is: it doesn’t matter. Pick
one.</p>
<h3 id="incomplete-input">Incomplete input</h3>
<p>The next issue is sentences that are incomplete, that need further
elaboration.</p>
<p><em>king slice princess</em></p>
<p>Slice her with what? His hands won’t work. He’ll need a tool. The
system will have to find something appropriate in the scene to use and
effectively rework the sentence internally as:</p>
<p><em>king slice princess using sword</em></p>
<p>With <em>king throw baseball</em> the issue is where. In this case, I
would usually interpret this to mean select a suitable indirect object,
something he could throw the baseball to, as in <em>king throw princess
baseball</em>.</p>
<h3 id="differences-in-degree">Differences in degree</h3>
<p>Then, different verbs can imply different degrees of effectiveness.
Can that be represented?</p>
<p><em>king nick princess</em></p>
<p>Nicking is probably less damaging than slicing. Certainly immolate is
be more severe than singe</p>
<h3 id="journalism-101">Journalism 101</h3>
<p>The more general issue of words that need filling in is answering
journalism’s classic questions: <em>who/what/where/when/why</em> and
<em>how</em>. Some of them are easy. <em>Who/what</em> will be the
subject, object, and indirect object. <em>Where</em> will be located in
the current scene tied to subject, object, or indirect object (unless
you say <em>king visit prison</em>, in which case we start in one scene
and end in another). <em>When</em> is now. <em>How</em> I interpret to
mean “with what tool”, though there are other meanings for how related
to adverbs of degree, for example. And for now <em>why</em> is easy:
“because the user said to”.</p>
<p>OK, so we take a user sentence of subject-verb-object and remap it to
contain subject-verb-object-indirectobject and tool. Is that it? No.</p>
<h3 id="generic-verbs">Generic verbs</h3>
<p><em>king shoot derringer vs king use derringer</em></p>
<p>There’s the question of performing generic actions. Shoot is a
specific action. Use is a generic action which in this context likely
means the same as shoot. But the effects of use vary depending on the
object of use, so objects need to know what their generic uses are and
submit revised sentences.</p>
<h3 id="generic-nouns">Generic Nouns</h3>
<p>Normally when the user mentions a noun, we create it or find it in
the scene. But not all nouns should be treated that way.</p>
<p><em>king throw object</em></p>
<p>Clearly that is a generic reference to an object and is not an object
to create. Neither, actually, is the word gun. There are many kinds of
guns, and it is really a generic word covering all sorts of specific
instances. So if the user says gun, we have to find or create a specific
kind of gun, allowing the user to enter both gun and colt-.45, if that’s
what we created.</p>
<h3 id="part-whole-relations">Part-Whole relations</h3>
<p>Then there’s <em>king pull trigger</em>. We don’t want to create a
free-standing trigger object and have the king pull it around in a wagon
(though maybe that would be funny). It’s a part of some other object.
And, in fact, the verb- noun pair together have an idiomatic meaning… we
are back to an equivalent of <em>king shoot gun</em>.</p>
<p>So we have to know parts of objects that refer us to those objects.
<em>King pull trigger</em> will need another internal reference - the
part. The fully decoded sentence is more like <em>King pull
machine-gun</em> (trigger) which becomes <em>King shoot machine-gun</em>
which becomes <em>King shoot princess using machine-gun</em>.</p>
<p>Similarly, part knowledge allows us to treat <em>king slice
finger</em> and <em>king slice eye</em> as having somewhat different
effects if we choose. In either case we have to impute the actual thing
we are damaging as well as the actual object to use as a tool.</p>
<h3 id="noun-elaboration">Noun Elaboration</h3>
<p>Then there is the need to sometimes expand upon what the user refers
to, to make it more useful.</p>
<p><em>king take anthrax</em>. Is that airborne anthrax, placing the
character already in danger or is it contained in a vial making it
transportable but available for use as a weapon. The system should
relabel the object to “vial of anthrax” when it reports back to the
user, and accept <em>anthrax</em> or <em>vial</em> in user input. This
makes it possible for the user to have useful expectations about how
things work.</p>
<p><em>king take bat</em> - The system could expand that to say
<em>baseball bat</em> or <em>flying bat</em>, to remove the
ambiguity.</p>
<p>And that’s what I’ve considered and managed so far. This stuff will
feed back into my chatbots eventually to improve them.</p>
<h2 id="summary">Summary</h2>
<p>Some people search for the meaning of life. I haven’t gotten to that
yet. I’m still searching on the meaning of meaning. My quest to have a
computer understand and manipulate meaning is a step or two closer. Only
a few thousand more to go.</p>
<p>I hope you found this story both entertaining and instructive. A copy
of this paper can be gotten from Alison. If you want to read anything
else I’ve written, you can just Google me. Meanwhile, I’m happy to take
any questions you now have.</p>
</body>
</html>
